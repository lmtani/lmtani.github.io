[ { "title": "Playing with bioinformatics I", "url": "/posts/playing-with-bioinformatics-I/", "categories": "Bioinformatics, File formats", "tags": "alignment, bwa, picard, crumble, samtools", "date": "2021-10-15 00:33:00 -0300", "snippet": "Bioinformatics is known to have plenty of file formats. Every time a discussion about file formats starts, I remember this comic.I’ll guide you through some of these formats in this post, always paying attention to our precious Illumina reads contents. Here is our plan: Download public data to play with. We’ll use the sars-cov-2 genome, and Illumina reads from a whole-genome amplicon experiment. Convert FASTQ files to unaligned BAM (uBAM), just to show how it works. Transform uBAM into a single interleave FASTQ file. Align FASTQs files (interleaved and paired) on the sars-cov-2 genome, creating a BAM file. Convert BAM to CRAM and also to a lossy CRAM Convert back from CRAM to pairs of FASTQsYou can find the shell script we use here in this GitHub repository.ToolsI’m assuming you are in a Unix-like system (ubuntu, fedora, WSL2, macOS, etc.) Picard - To convert FASTQ ⇄ uBAM and SAM ⇄ BAM ⇄ CRAM Samtools - To create .fai index BWA - To align reads to genome Crumble - To try lossy compression on alignment file See miniconda or Docker to easily get your environment ready. I plan to make a post about it soon.Download public datasetFirstly, go to a directory you like. For example, /tmp/bioinfo if you don’t want to persist files from this post after reboot your system.We’ll use two repositories to retrieve some data for our experiment: Sequence Read Archive (SRA): stores raw data from NGS sequencing experiments. FTP from NCBI/genomes: organizes information on genomes.Raw sequencing dataSRA organizes its data using unique identifiers, like this one under our GENOME_SRA_ID variable. If you want more information, visit ERR6335730 page to inspect.The tool fastq-dump is used to download reads and store them in two FASTQ files. One for R1 and the other for R2 reads.Reference sequenceUsually, reference sequences (or genomes) are stored in the FASTA format.In the code below, we download it with wget program, writing it as genome.fa.gz inside a directory. Then we decompress it with gunzip, and finally, we create a required index file (.fai) using samtools.Transforming readsHere we’ll transform our R1 and R2 files into two different formats, just to illustrate our diversity of file formats.The unaligned BAM formatIn this step, we’ll convert R1 and R2 reads into a single SAM-like file named unaligned BAM (uBAM). The significant advantage I see in this format is that one can store metadata in its header, so you can have pieces of information like the sequencing run name, the library, the date of the experiment, the facility it was sequenced so on.This is the format used by Broad Institute in their workflows.Here is how to have it:The interleaved FASTQ formatThis one is not as popular as the others, but I’ll mention it here just in case you see it out there. The two reads (R1 and R2) are in the same file and marked as /1 and /2 to inform their origin.Align to reference sequenceThis step usually is the most intense in genotyping workflows. This step is responsible for identifying where is the best region to align each of your NGS reads. There is a lot of complexity in this step, but it’s out of the scope of this post. For now, you can consider the best region as the interval where your sequencing read and the reference sequence are more similar.For comparison, we will align the pair of FASTQs (R1 and R2) and also the interleaved one.It creates two alignment files named BAM. Remember that whenever you see SAM/BAM/CRAM files, they essentially store the same information: how your reads align to the reference sequence. SAM is not compressed, and CRAM is smaller in file size. Note that you’ll need to use your reference sequence to restore information from CRAM files.Now that we have our BAM files, we can calculate some statistics using Picard. The goal in using this is to see that both files contain essentially the same data. Minor differences are expected.See that both stats have very similar metrics. From now on, we will use only the BAM obtained from the alignment of the interleaved FASTQ.# zgrep to select only some lines and columnszgrep -E &quot;^PAIR|^CATEGORY&quot; algn-from-pairs.bam.stats | cut -f 1,2,3,4,5,6,7,8 | column -tCATEGORY TOTAL_READS PF_READS PCT_PF_READS PF_NOISE_READS PF_READS_ALIGNED PCT_PF_READS_ALIGNED PF_ALIGNED_BASESPAIR 200000 200000 1 0 199302 0.99651 21604991zgrep -E &quot;^PAIR|^CATEGORY&quot; algn-from-interleaved.bam.stats | cut -f 1,2,3,4,5,6,7,8 | column -tCATEGORY TOTAL_READS PF_READS PCT_PF_READS PF_NOISE_READS PF_READS_ALIGNED PCT_PF_READS_ALIGNED PF_ALIGNED_BASESPAIR 200000 200000 1 0 199302 0.99651 21604976Storing as CRAM fileCRAM is the most compressed alignment format, and because of this, it’s usually the adopted form for long-term storage. From what I see in human genome/exome data, it’s about 1/3 of the equivalent BAM file.To create it: Remember: you will always need the reference sequence (FASTA) to decompress this format.Example of lossy compressionBecause of the amount of data that today’s sequencers can produce, storage is a challenge. You can use local or cloud-based systems, but the problem remains the same.Crumble is a tool to perform controlled loss of information to improve the compression of alignments. Here we’ll execute it with the most “aggressive” parameters to show how much smaller an alignment could be if we throw away some of its information.Alignment file size comparison BAM: 16M CRAM: 9.1M Lossy CRAM: 3.4MRecover raw reads from alignmentRemember that you aligned your reads into a reference sequence, and this alignment is stored as SAM/BAM/CRAM. So, if you don’t have used any destructive parameter, you could retrieve the same read information from the alignment. This is important because you could delete the original sequences or put them in a coldline storage system if you prefer. There are a lot of cloud storage categories where it’s cheap to store, but you’ll pay more if you need to retrieve the data.Here we compare the content of one read. Headers are different, and because of this, we need to compare the sequence and quality only.If you calculate the md5sum hash for these two files, you’ll see that they have the same content. You can also inspect it manually by opening in any text editor or using the cat command.# Originalzgrep -A 3 -w &quot;@ERR6335730.9&quot; ERR6335730_1.fastq.gz | grep -E -v &quot;^\\@|^\\+&quot;GAACTCACTTTCCATCCAACTTTTGTTGTTTTTGTGGTTAGAAGTAACACCCAAAAATGGATCATTACAAAATTGAAATTCACAGACTTTAATAACAACATTAGTAGCTGTCTCTTATACACATCTCCGAGCCCACGAGACGAGAATGGT&amp;gt;3AAAFFFFFFFFFGD4FFGGGHHGHHGHHHHGGHH2GFGFCHDGGFGHGGGGHEEGFFHHHHEGHBHHHHGHHHFGBGHHEFGHFHHGHHGHFHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHGGGEGGGGGGEGGFGCDDHHFH# Recovered from CRAMzgrep -A 3 -w &quot;@ERR6335730.9&quot; STEP_5/restored_R1.fq.gz | grep -E -v &quot;^\\@|^\\+&quot;GAACTCACTTTCCATCCAACTTTTGTTGTTTTTGTGGTTAGAAGTAACACCCAAAAATGGATCATTACAAAATTGAAATTCACAGACTTTAATAACAACATTAGTAGCTGTCTCTTATACACATCTCCGAGCCCACGAGACGAGAATGGT&amp;gt;3AAAFFFFFFFFFGD4FFGGGHHGHHGHHHHGGHH2GFGFCHDGGFGHGGGGHEEGFFHHHHEGHBHHHHGHHHFGBGHHEFGHFHHGHHGHFHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHGGGEGGGGGGEGGFGCDDHHFH# If you want to know how it stands after crumble# you could revert its CRAM to FASTQ and inspect.zgrep -A 3 -w &quot;@ERR6335730.9&quot; from-crumble_1.fq.gz | grep -E -v &quot;^\\@|^\\+&quot;GAACTCACTTTCCATCCAACTTTTGTTGTTTTTGTGGTTAGAAGTAACACCCAAAAATGGATCATTACAAAATTGAAATTCACAGACTTTAATAACAACATTAGTAGCTGTCTCTTATACACATCTCCGAGCCCACGAGACGAGAATGGT88DDDDDDDDDDDDD&amp;lt;&amp;lt;GGGGGGGGGGGGGGGGGGG2EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEThat’s it. Hope you find it helpful to get familiar with some common bioinformatics steps and file formats. Let me know if you have any questions or suggestions in the comments below.Comments Comments powered by Disqus. " }, { "title": "BLAST using Sequence Server", "url": "/posts/blast-using-sequence-server/", "categories": "Bioinformatics, Sequence Analysis", "tags": "BLAST", "date": "2021-10-06 00:33:00 -0300", "snippet": "IntroductionBLAST is one of the most used bioinformatics tools. It allows researchers to quickly find regions of similarity between a sequence of interest and a database with thousands of other sequences.Common scenarios You’ve sequenced an amplicon - e.g., using sanger - and want to know if the desired region was amplified. So you can align your sequence against the whole NCBI nucleotide database to infer it. You just received your FASTQ files with NGS data and want to know if it contains the desired specie. It’s not the best strategy, but one could copy the content of one read and align it using BLAST against the NCBI database. You’ve assembled a new genome for an organism that still does not exists in public databases. You can create a database with that species so you and your collaborators can align known sequences against it. For example, you have a gene of interest from a similar species and want to know where it is in your whole-genome assembly. Here we will configure a local instance of Sequence Server and configure it to store some genome and protein sequences.At the end of this tutorial, you’ll have a BLAST server like this oneRequirements Docker or PodmanIn the oficial documentation they show how to install it without Docker, but here we’ll follow with the containerized solution.Running Sequence ServerSequence Server developers distribute their container images through DockerHub. So in the following code snippet, we’re going to: Create a directory to store your FASTA sequences. Download a sample genome sequence just to get it running. Decompress it and move it to the above-created directory. Run makeblastdb to create a nucleotide database for this sequence. Run SequenceServer.# 1. Create directorymkdir my-database# 2. Download sample genomewget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/001/010/845/GCA_001010845.1_ASM101084v1/GCA_001010845.1_ASM101084v1_genomic.fna.gz# 3. Decompressgunzip GCA_001010845.1_ASM101084v1_genomic.fna.gz# Move to database directorymv GCA_001010845.1_ASM101084v1_genomic.fna my-database/# 4. Create BLAST dabase# Assuming you are at $HOME (ex: /home/your-user/)docker run -it \\ -v /tmp/blast/my-database:/db wurmlab/sequenceserver:2.0.0.rc8 \\ bash -c &quot; makeblastdb -dbtype nucl \\ -title &#39;Sporisorium scitamineum genome&#39; \\ -in /db/GCA_001010845.1_ASM101084v1_genomic.fna \\ -parse_seqids&quot;# 5. Run the Sequence Serverdocker run --rm -it -p 4567:4567 -v /tmp/blast/my-database:/db \\ wurmlab/sequenceserver:2.0.0.rc8And that is it. Now you have a BLAST Sequence Server running under you http://127.0.0.1:4567 address.Every time you want to add a new sequence to your database, you can execute step 4 for it. Note that if you want to make a protein database you’ll need to change the -dbtype, from nucl to prot.Comments Comments powered by Disqus. " } ]
